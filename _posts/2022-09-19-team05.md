---
layout: post
comments: true
title: 2 vs 2 soccer game
author: Linqiao Jiang, Qi Li, Huizhuo Yuan (Team 05)
date: 2022-09-19
---


> In this project we are going to investiage **self-play for compettive Multi-agent Reinforcement Learning (MARL)**. We will build a 2 vs 2 soccer game in Unity and try different MARL algorithms on it. We will provide the source code and detailed analysis.

<!--more-->
{: class="table-of-content"}
* TOC
{:toc}

---

## Project Proposal 

In this project we will investigate **self-play for compettive Multi-agent Reinforcement Learning (MARL)**. Different from single-agent systems, the evolution of the environmental state and the reward function that each agent received are not only determined by the envrionment, but also other agents' joint actions. As a result, agents need to take into account and interact with not only the environment but also other intelligent agents (see Fig. 1). In a multi-agents scenario, there could be cooperation (e.g., May and Cody in video game *It Takes Two*) and competition (e.g., most of board games).

<figure align="center">
  <img width="90%" src="../../../assets/images/team05/MARL.png">
  <figcaption>Fig 1. Single-agent vs Multi-agent [1].</figcaption>
</figure>



Concretely, our target is to implement a toy 2 vs 2 soccer game in Unity (as shown in Fig. 2). In this game, there are two teams with two agents in each. The goal is to get the ball into the opponent's goal while preventing the ball from entering own goal.

<figure align="center">
  <img width="80%" src="../../../assets/images/team05/soccer.png">
  <figcaption>Fig 2. 2 vs 2 soccer game in Unity [2].</figcaption>
</figure>



To achive this, we are going to firstly build up the soccer environment in Unity [2]. Then we plan to create a 1 vs 1 soccer game to investigate the behaviors of competition. After the 1 vs 1 scenario works, we will handle the 2 vs 2 soccer game which involves cooperation too.

We plan to implement some of the below **MARL algorithms** [3] and analyse their behaivors:

- Independent Learning
  - [IQL：Multi-Agent Reinforcement Learning: Independent vs. Cooperative Agents](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.84.3701&rep=rep1&type=pdf) [4]
- Value Decomposition
  - [VDN：Value-Decomposition Networks For Cooperative Multi-Agent Learning](https://arxiv.org/pdf/1706.05296) [5]
  - [QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning](http://proceedings.mlr.press/v80/rashid18a/rashid18a.pdf) [6]
  - [QTRAN: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/1905.05408) [7]
- Policy Gradient
  - [COMA：Counterfactual Multi-Agent Policy Gradients](https://arxiv.org/abs/1705.08926) [8]
  - [MADDPG：Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments](https://arxiv.org/pdf/1706.02275.pdf&quot;&gt;Multi-Agent) [9]
- Communication
  - [BiCNet：Multiagent Bidirectionally-Coordinated Nets: Emergence of Human-level Coordination in Learning to Play StarCraft Combat Games](https://arxiv.org/abs/1703.10069) [10]
  - [CommNet：Learning Multiagent Communication with Backpropagation](https://arxiv.org/abs/1605.07736) [11]
  - [IC3Net：Learning when to Communicate at Scale in Multiagent Cooperative and Competitive Tasks](https://arxiv.org/abs/1812.09755) [12]
  - [RIAL/RIDL：Learning to Communicate with Deep Multi-Agent Reinforcement Learning](https://arxiv.org/abs/1605.06676) [13]
- Exploration
  - [MAVEN：Multi-Agent Variational Exploration](https://arxiv.org/pdf/1910.07483) [14]

Hopefully, we can build a game environment like this:

<p align="center">
	<iframe width="618" height="473" src="https://www.youtube.com/embed/Hg3nmYD3DjQ" frameborder="0" allowfullscreen ng-show="showvideo"></iframe>
</p>

We will also create a GUI to allow users to flight with RL agents, if time allows.

It is possible that some algorithms don't work well in the soccer settings. We will try to finetune the hyper-parameters and analyse why some of the algorithms fail.

By this project, we hope to provide a easy-to-use multi-agent environment and plug-and-play MARL algorithms to class and, also give detailed analysis of behaviors of MARL agents to readers.

## References

1. https://arxiv.org/pdf/2011.00583.pdf 
2. https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Learning-Environment-Examples.md#soccer-twos
3. https://github.com/TimeBreaker/MARL-papers-with-code/blob/main/README.md
4. https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.84.3701&rep=rep1&type=pdf
5. https://arxiv.org/pdf/1706.05296
6. http://proceedings.mlr.press/v80/rashid18a/rashid18a.pdf
7. https://arxiv.org/abs/1905.05408
8. https://arxiv.org/abs/1705.08926
9. https://arxiv.org/pdf/1706.02275.pdf&quot;&gt;Multi-Agent
10. https://arxiv.org/abs/1703.10069
11. https://arxiv.org/abs/1605.07736
12. https://arxiv.org/abs/1812.09755
13. https://arxiv.org/abs/1605.06676
14. https://arxiv.org/pdf/1910.07483
